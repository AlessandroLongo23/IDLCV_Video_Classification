{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = {\n",
    "    'output_aggregation': {},\n",
    "    'late_fusion_mlp': {},\n",
    "    'late_fusion_pooling': {},\n",
    "    'early_fusion': {},\n",
    "    '3D_CNN': {},\n",
    "    'dual_stream': {},\n",
    "}\n",
    "\n",
    "for category in test_results:\n",
    "    test_results[category] = {\n",
    "        'with_leakage': {},\n",
    "        'without_leakage': {}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. With leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.globalConst import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from DatasetLoader.FrameImageDataset import FrameImageDataset\n",
    "from DatasetLoader.FrameVideoDataset import FrameVideoDataset\n",
    "\n",
    "train_transform = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.RandomRotation(5),\n",
    "    T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "val_test_transform = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    T.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "## 1.2. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Output aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameimage_train_loader = DataLoader(\n",
    "    dataset=FrameImageDataset(split='train', transform=train_transform, leakage=True), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "frameimage_val_loader = DataLoader(\n",
    "    dataset=FrameImageDataset(split='val', transform=val_test_transform, leakage=True), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "frameimage_test_loader = DataLoader(\n",
    "    dataset=FrameImageDataset(split='test', transform=val_test_transform, leakage=True), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framevideolist_train_loader = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='train', transform=train_transform, leakage=True, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "framevideolist_val_loader = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='val', transform=val_test_transform, leakage=True, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "framevideolist_test_loader = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='test', transform=val_test_transform, leakage=True, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.OutputAggregation import OutputAggregation\n",
    "\n",
    "model = OutputAggregation(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_loader=frameimage_train_loader,\n",
    "    val_loader=frameimage_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['output_aggregation']['with_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    test_loader=frameimage_test_loader\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Late fusion with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.LateFusionMLP import LateFusionMLP\n",
    "\n",
    "model = LateFusionMLP(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_loader=framevideolist_train_loader,\n",
    "    val_loader=framevideolist_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['late_fusion_mlp']['with_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    test_loader=framevideolist_test_loader\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Late fusion with Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.LateFusionPooling import LateFusionPooling\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = LateFusionPooling(device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_loader=framevideolist_train_loader,\n",
    "    val_loader=framevideolist_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['late_fusion_pooling']['with_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    test_loader=framevideolist_test_loader\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.4. Early fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.EarlyFusion import EarlyFusion\n",
    "\n",
    "model = EarlyFusion(device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_loader=framevideolist_train_loader,\n",
    "    val_loader=framevideolist_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['early_fusion']['with_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    test_loader=framevideolist_test_loader\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.5. 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.CNN3D import CNN3D\n",
    "\n",
    "model = CNN3D(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True),\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    train_loader=framevideolist_train_loader,\n",
    "    val_loader=framevideolist_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['3D_CNN']['with_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(),\n",
    "    test_loader=framevideolist_test_loader\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 2. Without leakage\n",
    "\n",
    "## 2.1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameimage_train_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameImageDataset(split='train', transform=train_transform, leakage=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "frameimage_val_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameImageDataset(split='val', transform=val_test_transform, leakage=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "frameimage_test_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameImageDataset(split='test', transform=val_test_transform, leakage=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framevideolist_train_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='train', transform=train_transform, leakage=False, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "framevideolist_val_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='val', transform=val_test_transform, leakage=False, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "framevideolist_test_loader_no_leakage = DataLoader(\n",
    "    dataset=FrameVideoDataset(split='test', transform=val_test_transform, leakage=False, stack_frames=False), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1. Output aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.OutputAggregation import OutputAggregation\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = OutputAggregation(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=criterion,\n",
    "    train_loader=frameimage_train_loader_no_leakage,\n",
    "    val_loader=frameimage_val_loader_no_leakage,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['output_aggregation']['without_leakage'] = model.eval_( \n",
    "    criterion=criterion,\n",
    "    test_loader=frameimage_test_loader_no_leakage\n",
    ")\n",
    "\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2. Late fusion with MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.LateFusionMLP import LateFusionMLP\n",
    "\n",
    "model = LateFusionMLP(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=criterion,\n",
    "    train_loader=framevideolist_train_loader_no_leakage,\n",
    "    val_loader=framevideolist_val_loader_no_leakage,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['late_fusion_mlp']['without_leakage'] = model.eval_(\n",
    "    criterion=criterion,\n",
    "    test_loader=framevideolist_test_loader_no_leakage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3. Late fusion with Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.LateFusionPooling import LateFusionPooling\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "model = LateFusionPooling(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=criterion,\n",
    "    train_loader=framevideolist_train_loader_no_leakage,\n",
    "    val_loader=framevideolist_val_loader_no_leakage,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['late_fusion_pooling']['without_leakage'] = model.eval_(\n",
    "    criterion=criterion,\n",
    "    test_loader=framevideolist_test_loader_no_leakage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4. Early fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.EarlyFusion import EarlyFusion\n",
    "\n",
    "model = EarlyFusion(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "    train_loader=framevideolist_train_loader_no_leakage,\n",
    "    val_loader=framevideolist_val_loader_no_leakage,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['early_fusion']['without_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "    test_loader=framevideolist_test_loader_no_leakage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5. 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.CNN3D import CNN3D\n",
    "\n",
    "model = CNN3D(device).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5),\n",
    "    criterion=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "    train_loader=framevideolist_train_loader_no_leakage,\n",
    "    val_loader=framevideolist_val_loader_no_leakage,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['3D_CNN']['without_leakage'] = model.eval_(\n",
    "    criterion=nn.CrossEntropyLoss(label_smoothing=0.1),\n",
    "    test_loader=framevideolist_test_loader_no_leakage\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- - -\n",
    "- - -\n",
    "# 3. Dual Stream model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_transform = T.Compose([\n",
    "    T.Resize((IMAGE_SIZE, IMAGE_SIZE)),                   \n",
    "    T.Normalize(mean=[0.5] * 2, std=[0.5] * 2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DatasetLoader.FlowVideoDataset import FlowVideoDataset\n",
    "\n",
    "flowvideo_train_loader = DataLoader(\n",
    "    dataset=FlowVideoDataset(split='train', transform=flow_transform), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "flowvideo_val_loader = DataLoader(\n",
    "    dataset=FlowVideoDataset(split='val', transform=flow_transform), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "flowvideo_test_loader = DataLoader(\n",
    "    dataset=FlowVideoDataset(split='test', transform=flow_transform), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_labels = [label for _, label in frameimage_train_loader.dataset]\n",
    "class_counts = Counter(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "classes = np.unique(train_labels)\n",
    "class_weights = compute_class_weight('balanced', classes=classes, y=train_labels)\n",
    "print(f\"Class Counts: {class_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(f\"Class Weights: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Models.DualStream import DualStream\n",
    "model = DualStream(device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_(\n",
    "    num_epochs=5,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criterion=criterion,\n",
    "    train_loader=flowvideo_train_loader,\n",
    "    val_loader=flowvideo_val_loader,\n",
    "    plot=True\n",
    ")\n",
    "\n",
    "test_results['dual_stream']['without_leakage'] = model.eval_(\n",
    "    criterion=criterion,\n",
    "    test_loader=flowvideo_test_loader\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
